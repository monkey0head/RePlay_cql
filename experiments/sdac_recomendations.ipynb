{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e51a1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rs_datasets import MovieLens\n",
    "from d3rlpy.base import LearnableBase\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "from d3rlpy.models.optimizers import OptimizerFactory, AdamFactory\n",
    "from pyspark.sql import functions as sf, DataFrame\n",
    "import numpy as np\n",
    "from typing import Optional, Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34037e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MovieLens(version=\"1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d619bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating  timestamp\n",
       "0              1     1193       5  978300760\n",
       "1              1      661       3  978302109\n",
       "2              1      914       3  978301968\n",
       "3              1     3408       4  978300275\n",
       "4              1     2355       5  978824291\n",
       "...          ...      ...     ...        ...\n",
       "1000204     6040     1091       1  956716541\n",
       "1000205     6040     1094       5  956704887\n",
       "1000206     6040      562       5  956704746\n",
       "1000207     6040     1096       4  956715648\n",
       "1000208     6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09863d3",
   "metadata": {},
   "source": [
    "### Data to MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d75e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data(log: DataFrame) -> MDPDataset:\n",
    "        use_negative_events = True #False\n",
    "        rating_based_reward = True #False\n",
    "        reward_top_k = True\n",
    "        k = 10\n",
    "        \n",
    "        test_size = 0.3\n",
    "        action_randomization_scale = 0.3\n",
    "        raw_rating_to_reward_rescale = {\n",
    "        1.0: -1.0,\n",
    "        2.0: -0.3,\n",
    "        3.0: 0.25,\n",
    "        4.0: 0.7,\n",
    "        5.0: 1.0,\n",
    "    }\n",
    "        binary_rating_to_reward_rescale = {\n",
    "            1.0: -1.0,\n",
    "            2.0: -1.0,\n",
    "            3.0: 1.0,\n",
    "            4.0: 1.0,\n",
    "            5.0: 1.0,\n",
    "        }\n",
    "        if not use_negative_events:\n",
    "            # remove negative events\n",
    "            log = log.filter(sf.col('rating') >= sf.lit(3.0))\n",
    "\n",
    "        # TODO: consider making calculations in Spark before converting to pandas\n",
    "        user_logs = log.sort_values(['user_id', 'timestamp'], ascending=True)\n",
    "\n",
    "        if rating_based_reward:\n",
    "            rescale = raw_rating_to_reward_rescale\n",
    "        else:\n",
    "            rescale = binary_rating_to_reward_rescale\n",
    "        rewards = user_logs['rating'].map(rescale).to_numpy()\n",
    "\n",
    "        if reward_top_k:\n",
    "            # additionally reward top-K watched movies\n",
    "            user_top_k_idxs = (\n",
    "                \n",
    "                user_logs\n",
    "                .sort_values(['rating', 'timestamp'], ascending=[False, True])\n",
    "                .groupby('user_id')\n",
    "                .head(k)\n",
    "                .index\n",
    "            )\n",
    "            # rescale positives and additionally reward top-K watched movies\n",
    "            rewards[rewards > 0] /= 2\n",
    "            rewards[user_top_k_idxs] += 0.5\n",
    "\n",
    "        user_logs['rewards'] = rewards\n",
    "\n",
    "        # every user has his own episode (the latest item is defined as terminal)\n",
    "        user_terminal_idxs = (\n",
    "            user_logs[::-1]\n",
    "            .groupby('user_id')\n",
    "            .head(1)\n",
    "            .index\n",
    "        )\n",
    "        terminals = np.zeros(len(user_logs))\n",
    "        terminals[user_terminal_idxs] = 1\n",
    "        user_logs['terminals'] = terminals\n",
    "\n",
    "        # cannot set zero scale as d3rlpy will treat transitions as discrete :/\n",
    "        \n",
    "        \n",
    "        #разбиение на трейн тест\n",
    "        user_id_list = list(set(user_logs['user_id']))\n",
    "        count_of_test = int(test_size*len(user_id_list))\n",
    "        test_idx = int(user_id_list[-count_of_test])\n",
    "        \n",
    "        user_logs_train = user_logs[user_logs['user_id'].astype(int) < test_idx]\n",
    "        user_logs_test = user_logs[user_logs['user_id'].astype(int) >= test_idx]\n",
    "        \n",
    "        action_randomization_scale = action_randomization_scale + 1e-4\n",
    "        action_randomization = np.random.randn(len(user_logs_train)) * action_randomization_scale\n",
    "\n",
    "        train_dataset = MDPDataset(\n",
    "            observations=np.array(user_logs_train[['user_id', 'item_id']]),\n",
    "            actions=np.array(\n",
    "                user_logs_train['rating'] + action_randomization\n",
    "            )[:, None],\n",
    "            rewards=user_logs_train['rewards'],\n",
    "            terminals=user_logs_train['terminals']\n",
    "        )\n",
    "        test_dataset = MDPDataset(\n",
    "            observations=np.array(user_logs_test[['user_id', 'item_id']]),\n",
    "            actions=np.array(\n",
    "                user_logs_test['rating']\n",
    "            )[:, None],\n",
    "            rewards=user_logs_test['rewards'],\n",
    "            terminals=user_logs_test['terminals']\n",
    "        )\n",
    "        return train_dataset, user_logs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2eb0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _predict(\n",
    "    model,\n",
    "    log: DataFrame = None,\n",
    "    k: int = 10,\n",
    "    users: DataFrame = None,\n",
    "    items: DataFrame = None,\n",
    "    user_features: Optional[DataFrame] = None,\n",
    "    item_features: Optional[DataFrame] = None,\n",
    "    filter_seen_items: bool = True,\n",
    ") -> DataFrame:\n",
    "    if user_features or item_features:\n",
    "        message = f'RL recommender does not support user/item features'\n",
    "      #  self.logger.debug(message)\n",
    "\n",
    "    users = np.array(users).flatten()\n",
    "    items = np.array(items).flatten()\n",
    "\n",
    "    # TODO: consider size-dependent batch prediction instead of by user\n",
    "    user_predictions = []\n",
    "    for user in users:\n",
    "        user_item_pairs = pd.DataFrame({\n",
    "            'user_idx': np.repeat(user, len(items)),\n",
    "            'item_idx': items\n",
    "        })\n",
    "        user_item_pairs['relevance'] = model.predict(user_item_pairs.to_numpy())\n",
    "        user_predictions.append(user_item_pairs)\n",
    "\n",
    "    prediction = pd.concat(user_predictions)\n",
    "    prediction = prediction.sort_values(['relevance'])[::-1][:k]\n",
    "    # it doesn't explicitly filter seen items and doesn't return top k items\n",
    "    # instead, it keeps all predictions as is to be filtered further by base methods\n",
    "    return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8d28f",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf0d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  \n",
    "def ndcg(k, pred, ground_truth) -> float:\n",
    "        pred_len = min(k, len(pred))\n",
    "        ground_truth_len = min(k, len(ground_truth))\n",
    "        denom = [1 / math.log2(i + 2) for i in range(k)]\n",
    "        dcg = sum(denom[i] for i in range(pred_len) if pred[i] in ground_truth)\n",
    "        idcg = sum(denom[:ground_truth_len])\n",
    "\n",
    "        return dcg / idcg\n",
    "    \n",
    "def mape(k, pred, ground_truth) -> float:\n",
    "        length = min(k, len(pred))\n",
    "        max_good = min(k, len(ground_truth))\n",
    "        if len(ground_truth) == 0 or len(pred) == 0:\n",
    "            return 0\n",
    "        tp_cum = 0\n",
    "        result = 0\n",
    "        for i in range(length):\n",
    "            if pred[i] in ground_truth:\n",
    "                tp_cum += 1\n",
    "                result += tp_cum / ((i + 1) * max_good)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79bbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_for_user(df, target, k = 10):\n",
    "    mask = df['user_id'] == target\n",
    "    user_relevance = df[mask]\n",
    "    return user_relevance.sort_values(['rating'])[::-1][:k]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea06cb2",
   "metadata": {},
   "source": [
    "### Fake env for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776d6d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbabycar27\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zoya/Documents/recsys/wandb/run-20221024_184339-232294yf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/babycar27/RecommendationsSDAC/runs/232294yf\" target=\"_blank\">atomic-terrain-5</a></strong> to <a href=\"https://wandb.ai/babycar27/RecommendationsSDAC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box, Tuple\n",
    "import wandb\n",
    "\n",
    "exp = wandb.init(project=\"RecommendationsSDAC\", group = \"MovieLens\")\n",
    "\n",
    "class FakeRecomenderEnv(gym.Env):\n",
    "    def __init__(self, test_data, top_k):\n",
    "        self.action_space = gym.spaces.Discrete(5)\n",
    "        self.observation_space = Box(0,100000, (2,))\n",
    "        self.log_data = test_data\n",
    "        self.top_k = top_k\n",
    "        self.steps = 0\n",
    "        self.episode_num = 0\n",
    "        self.episodes = list(set(self.log_data['user_id']))\n",
    "        self.total_episodes = 0\n",
    "        #mask = self.log_data['user_id'] == episodes[episode_num]\n",
    "        self.current_episode = None\n",
    "\n",
    "    def step(self, action): \n",
    "        self.relevance_hist.append(action)\n",
    "        done = False\n",
    "        reward = 0\n",
    "        ob = (self.current_episode['user_id'].values[self.steps], \n",
    "                self.current_episode['item_id'].values[self.steps])\n",
    "        self.steps += 1\n",
    "        if len(self.current_episode['user_id']) == self.steps:\n",
    "            done = True\n",
    "          #  print(len(self.user_hist), len(self.item_hist), len(self.relevance_hist))\n",
    "            pred_df = pd.DataFrame({'user_id': self.user_hist, 'item_hist': self.item_hist,\n",
    "                                    'relevance': self.relevance_hist})\n",
    "            pred_top_k = pred_df.sort_values(['relevance'])[::-1][:self.top_k]\n",
    "            reward = ndcg(10, pred_top_k['relevance'].values, self.original['rating'].values)\n",
    "            mape_ = mape(10, pred_top_k['relevance'].values, self.original['rating'].values)\n",
    "            exp.log({\"episode\": self.total_episodes, \"NDCG\": reward, \"MAP\": mape_})\n",
    "            ob = []\n",
    "        else:\n",
    "            self.user_hist.append(self.current_episode['user_id'].values[self.steps])\n",
    "            self.item_hist.append(self.current_episode['item_id'].values[self.steps])\n",
    "        \n",
    "        return np.asarray(ob), reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.user_hist = []\n",
    "        self.item_hist = []\n",
    "        self.relevance_hist = []\n",
    "        self.total_episodes += 1\n",
    "        self.episode_num += 1\n",
    "        if self.episode_num == len(self.episodes):\n",
    "            self.episode_num = 0\n",
    "        self.steps = 0 \n",
    "        mask = self.log_data['user_id'] == self.episodes[self.episode_num]\n",
    "        self.current_episode = self.log_data[mask]\n",
    "       # print(self.current_episode['user_id'])\n",
    "        self.user_hist.append(self.current_episode['user_id'].values[0])\n",
    "        self.item_hist.append( self.current_episode['item_id'].values[0])\n",
    "        self.original = original_for_user(self.log_data, self.current_episode['user_id'].values[0], k = self.top_k)\n",
    "        obs = self.current_episode['user_id'].values[0], \\\n",
    "                       self.current_episode['item_id'].values[0]\n",
    "      #  print( np.asarray(obs))\n",
    "        return np.asarray(obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ab84a",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8095d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,user_logs_train = _prepare_data(ds.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a27337",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FakeRecomenderEnv(user_logs_train, 10)\n",
    "\n",
    "from d3rlpy.metrics.scorer import evaluate_on_environment\n",
    "evaluate_scorer = evaluate_on_environment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9df9282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 1198], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1fba24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SDAC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sdac \u001b[38;5;241m=\u001b[39m \u001b[43mSDAC\u001b[49m(use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SDAC' is not defined"
     ]
    }
   ],
   "source": [
    "sdac = SDAC(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d52852ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msdac\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_dataset,\n\u001b[1;32m      2\u001b[0m         eval_episodes\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m      3\u001b[0m         n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#         n_steps = 100000,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#         n_steps_per_epoch=3000,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         scorers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluate_scorer})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdac' is not defined"
     ]
    }
   ],
   "source": [
    "sdac.fit(train_dataset,\n",
    "        eval_episodes=train_dataset,\n",
    "        n_epochs=3,\n",
    "#         n_steps = 100000,\n",
    "#         n_steps_per_epoch=3000,\n",
    "        scorers={'environment': evaluate_scorer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12391a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c19a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
