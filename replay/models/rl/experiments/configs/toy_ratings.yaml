# runner type tag
_type_: test.toy_ratings
# wandb project
project: recsys_toy_ratings
# wandb logging
log: True

seed: 42
cuda_device: ...

top_k: 10
epochs: 200

dataset:
  _type_: dataset.toy_ratings
  global_config: ???
  seed: ???
  source:
    _type_: ds_source.random
    seed: ???
    n_users: 100
    n_items: 100
    n_pairs: 0.2
    duplicates: False

  embeddings_n_dims: 7
  user_embeddings:
    _base_: embeddings.clusters
  item_embeddings:
    _base_: embeddings.clusters

  ratings:
    metric: l1
    positive_ratio: 0.1

augmentations:
  n_pairs: 0.0

train_test_split:
  split_by: user
  train: 0.25

mdp:
  actions: continuous
  rewards:
    baseline: [0.0, 0.0]
    continuous: 0.5
    discrete: [0.5, 0.5]
    continuous_error: 0.5
    discrete_error: 0.5

model:
  _base_: models.cql
  actor_learning_rate: 1e-3
  critic_learning_rate: 3e-3
  batch_size: 32

eval_schedule: 10

models:
  default:
    actor_learning_rate: 1e-4
    critic_learning_rate: 3e-4
    temp_learning_rate: 1e-4  #?
    alpha_learning_rate: 1e-4 # ?
    q_func_factory: "mean"
    batch_size: 256
    n_frames: 1
    n_steps: 1
    gamma: 0.99
    tau: 0.005
    n_critics: 2
    initial_temperature: 1.0  #?
    initial_alpha: 1.0  #?
    alpha_threshold: 10.0 # ?
    conservative_weight: 5.0 # ?
    n_action_samples: 10  #?
    soft_q_backup: False  #?
  cql:
    _type_: d3rlpy.cql
    _base_: default
    actor_learning_rate: 1e-3
    critic_learning_rate: 3e-3
    temp_learning_rate: 1e-4
    alpha_learning_rate: 1e-4
    alpha_threshold: 10.0
    conservative_weight: 5.0
    initial_temperature: 1.0
    initial_alpha: 1.0
    n_action_samples: 10
    soft_q_backup: False
  sac:
    _type_: d3rlpy.sac
    _base_: default
  ddpg:
    _type_: d3rlpy.ddpg
    _base_: default
    temp_learning_rate: 1e-4
    initial_temperature: 1.0
  discrete_cql:
    _type_: d3rlpy.discrete_cql
    _base_: default
  sdac:
    _type_: d3rlpy.sdac
    _base_: default
  discrete_sac:
    _type_: d3rlpy.discrete_sac
    _base_: default


embeddings:
  random:
    _type_: embeddings.random
    seed: ???
    n_dims: ???

  clusters:
    _type_: embeddings.clusters
    seed: ???
    n_dims: ???
    n_clusters: [2, 1, 4, 1, 2]
    intra_cluster_noise_scale: 0.05
    n_dissimilar_dims_required: 3
    min_dim_delta: 0.3
    min_l2_dist: 0.1
    max_generation_tries: 10000

#dataset_preparer:
#
#mdp:
#  _type_: mdp
#  use_negative_events: True
#  rating_based_reward: False
#  reward_top_k: True
#  rating_actions: False
#  action_randomization_scale: 0.01
#
#  raw_rating_to_reward_rescale:
#    1.0: -1.0
#    2.0: -0.3
#    3.0: 0.25
#    4.0: 0.7
#    5.0: 1.0
#
#  binary_rating_to_reward_rescale:
#    1.0: -1.0
#    2.0: -1.0
#    3.0: 1.0
#    4.0: 1.0
#    5.0: 1.0
#
#dataset_preparers:
#  split_by: timestamp
#  train_ratio: 0.8
#  test_ratio: 0.2
#
#
#datasets:
#  random:
#    _type_: ds.random
#    n_users: ???
#    n_items: ???
#    pairs: ???
#    test_ratio: 0.2
#  rs_dataset:
#    _type_: ds.rs_dataset
#    name: MovieLens.100k
#    test_ratio: 0.2
